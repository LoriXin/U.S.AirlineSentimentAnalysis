# -*- coding: utf-8 -*-
"""CapstoneFinal.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lAIVvwupL6w9-Gx4eaLDGqoIuMrmYz9B

# BERT
"""

import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments
from torch.optim import AdamW
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix
import pandas as pd
import time
from torch.utils.data import Dataset, DataLoader

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

df = pd.read_parquet('/content/0000.parquet')
print(df.head())

sentiment_mapping = {'negative': 0, 'neutral': 1, 'positive': 2}
df['sentiment_label'] = df['airline_sentiment'].map(sentiment_mapping)

texts = df['text'].tolist()
labels = df['sentiment_label'].tolist()

X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)

model_name = "bert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)

max_length = 64

class SentimentDataset(Dataset):
    def __init__(self, texts, labels, tokenizer, max_length=64):
        self.encodings = tokenizer(texts, truncation=True, padding="max_length", max_length=max_length)
        self.labels = labels

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx])
        return item

train_dataset = SentimentDataset(X_train, y_train, tokenizer, max_length)
test_dataset = SentimentDataset(X_test, y_test, tokenizer, max_length)

optimizer = AdamW(model.parameters(), lr=2e-5)

epochs = range(1, 7)
accuracy_results = []
f1_results = []
recall_results = []

best_epoch = 0
best_accuracy = 0.0
best_f1 = 0.0
best_recall = 0.0

for num_epochs in epochs:
    training_args = TrainingArguments(
        output_dir=f'./results_{num_epochs}',
        num_train_epochs=num_epochs,
        per_device_train_batch_size=8,
        per_device_eval_batch_size=8,
        warmup_steps=500,
        weight_decay=0.01,
        logging_dir=f'./logs_{num_epochs}',
        evaluation_strategy="epoch",
        save_strategy="epoch",
        load_best_model_at_end=True,
        save_total_limit=2,
        logging_steps=500,
    )

    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=test_dataset,
        optimizers=(optimizer, None)
    )

    start_train_time = time.time()
    trainer.train()
    train_time = time.time() - start_train_time

    start_infer_time = time.time()
    predictions = trainer.predict(test_dataset)
    infer_time = (time.time() - start_infer_time) / len(test_dataset)

    y_pred = torch.argmax(torch.tensor(predictions.predictions), axis=1).numpy()

    acc = accuracy_score(y_test, y_pred)
    f1_macro = f1_score(y_test, y_pred, average='macro')
    f1_micro = f1_score(y_test, y_pred, average='micro')
    f1_weighted = f1_score(y_test, y_pred, average='weighted')
    recall_macro = recall_score(y_test, y_pred, average='macro')
    recall_micro = recall_score(y_test, y_pred, average='micro')
    recall_weighted = recall_score(y_test, y_pred, average='weighted')
    precision_macro = precision_score(y_test, y_pred, average='macro')
    precision_micro = precision_score(y_test, y_pred, average='micro')
    precision_weighted = precision_score(y_test, y_pred, average='weighted')
    cm = confusion_matrix(y_test, y_pred)

    num_params = sum(p.numel() for p in model.parameters())

    print(f"=== Epoch {num_epochs} ===")
    print(f"Accuracy: {acc:.4f}")
    print(f"Precision - Macro: {precision_macro:.4f}, Micro: {precision_micro:.4f}, Weighted: {precision_weighted:.4f}")
    print(f"Recall    - Macro: {recall_macro:.4f}, Micro: {recall_micro:.4f}, Weighted: {recall_weighted:.4f}")
    print(f"F1-Score  - Macro: {f1_macro:.4f}, Micro: {f1_micro:.4f}, Weighted: {f1_weighted:.4f}")
    print("Confusion Matrix:")
    print(cm)
    print(f"Model Parameter Size: {num_params}")
    print(f"Training Time per Epoch: {train_time:.2f} seconds")
    print(f"Inference Time per Sample: {infer_time:.4f} seconds")

    accuracy_results.append(acc)
    f1_results.append(f1_weighted)
    recall_results.append(recall_weighted)

    if acc > best_accuracy:
        best_epoch = num_epochs
        best_accuracy = acc
        best_f1 = f1_weighted
        best_recall = recall_weighted

print(f"\nBEST Epoch: {best_epoch}")
print(f"BEST Accuracy: {best_accuracy:.4f}")
print(f"BEST F1-score (weighted): {best_f1:.4f}")
print(f"BEST Recall (weighted): {best_recall:.4f}")

print("Accuracy Curve:", accuracy_results)
print("F1 Curve:", f1_results)
print("Recall Curve:", recall_results)

"""Results:
BERTï¼š
Best Epoch: 2
Best Accuracy: 0.8521
Best F1-score: 0.8525
Best Recall: 0.8521

# DistilBERT
"""

import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments
from torch.optim import AdamW
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix
import pandas as pd
import time
from torch.utils.data import Dataset

df = pd.read_parquet('/content/0000.parquet')
print(df.head())

sentiment_mapping = {'negative': 0, 'neutral': 1, 'positive': 2}
df['sentiment_label'] = df['airline_sentiment'].map(sentiment_mapping)

texts = df['text'].tolist()
labels = df['sentiment_label'].tolist()

X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)

model_name = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)

max_length = 64

class SentimentDataset(Dataset):
    def __init__(self, texts, labels, tokenizer, max_length=64):
        self.encodings = tokenizer(texts, truncation=True, padding="max_length", max_length=max_length)
        self.labels = labels

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx])
        return item

train_dataset = SentimentDataset(X_train, y_train, tokenizer, max_length)
test_dataset = SentimentDataset(X_test, y_test, tokenizer, max_length)

optimizer = AdamW(model.parameters(), lr=2e-5)

epochs = range(1, 7)
accuracy_results = []
f1_results = []
recall_results = []

best_epoch = 0
best_accuracy = 0.0
best_f1 = 0.0
best_recall = 0.0

for num_epochs in epochs:
    training_args = TrainingArguments(
        output_dir=f'./results_{num_epochs}',
        num_train_epochs=num_epochs,
        per_device_train_batch_size=8,
        per_device_eval_batch_size=8,
        warmup_steps=500,
        weight_decay=0.01,
        logging_dir=f'./logs_{num_epochs}',
        evaluation_strategy="epoch",
        save_strategy="epoch",
        load_best_model_at_end=True,
        save_total_limit=2,
        logging_steps=500,
    )

    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=test_dataset,
        optimizers=(optimizer, None)
    )

    start_train_time = time.time()
    trainer.train()
    train_time = time.time() - start_train_time

    start_infer_time = time.time()
    predictions = trainer.predict(test_dataset)
    infer_time = (time.time() - start_infer_time) / len(test_dataset)

    y_pred = torch.argmax(torch.tensor(predictions.predictions), axis=1).numpy()

    acc = accuracy_score(y_test, y_pred)
    f1_macro = f1_score(y_test, y_pred, average='macro')
    f1_micro = f1_score(y_test, y_pred, average='micro')
    f1_weighted = f1_score(y_test, y_pred, average='weighted')
    recall_macro = recall_score(y_test, y_pred, average='macro')
    recall_micro = recall_score(y_test, y_pred, average='micro')
    recall_weighted = recall_score(y_test, y_pred, average='weighted')
    precision_macro = precision_score(y_test, y_pred, average='macro')
    precision_micro = precision_score(y_test, y_pred, average='micro')
    precision_weighted = precision_score(y_test, y_pred, average='weighted')
    cm = confusion_matrix(y_test, y_pred)

    num_params = sum(p.numel() for p in model.parameters())

    print(f"=== Epoch {num_epochs} ===")
    print(f"Accuracy: {acc:.4f}")
    print(f"Precision - Macro: {precision_macro:.4f}, Micro: {precision_micro:.4f}, Weighted: {precision_weighted:.4f}")
    print(f"Recall    - Macro: {recall_macro:.4f}, Micro: {recall_micro:.4f}, Weighted: {recall_weighted:.4f}")
    print(f"F1-Score  - Macro: {f1_macro:.4f}, Micro: {f1_micro:.4f}, Weighted: {f1_weighted:.4f}")
    print("Confusion Matrix:")
    print(cm)
    print(f"Model Parameter Size: {num_params}")
    print(f"Training Time per Epoch: {train_time:.2f} seconds")
    print(f"Inference Time per Sample: {infer_time:.4f} seconds")

    accuracy_results.append(acc)
    f1_results.append(f1_weighted)
    recall_results.append(recall_weighted)

    if acc > best_accuracy:
        best_epoch = num_epochs
        best_accuracy = acc
        best_f1 = f1_weighted
        best_recall = recall_weighted

print(f"\nBest Epoch: {best_epoch}")
print(f"BEST Accuracy: {best_accuracy:.4f}")
print(f"BEST F1-score (weighted): {best_f1:.4f}")
print(f"BEST Recall (weighted): {best_recall:.4f}")

print("Accuracy Curve:", accuracy_results)
print("F1 Curve:", f1_results)
print("Recall Curve:", recall_results)

"""# CNN"""

import torch
import torch.nn as nn
from torch.optim import AdamW
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix
import pandas as pd
import time
from torch.utils.data import Dataset, DataLoader
from transformers import AutoTokenizer

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

df = pd.read_parquet('/content/0000.parquet')
print(df.head())

sentiment_mapping = {'negative': 0, 'neutral': 1, 'positive': 2}
df['sentiment_label'] = df['airline_sentiment'].map(sentiment_mapping)

texts = df['text'].tolist()
labels = df['sentiment_label'].tolist()

X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)

tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased")

max_length = 64

class SentimentDataset(Dataset):
    def __init__(self, texts, labels, tokenizer, max_length=64):
        self.encodings = tokenizer(texts, truncation=True, padding="max_length", max_length=max_length)
        self.input_ids = torch.tensor(self.encodings["input_ids"], dtype=torch.long)
        self.labels = torch.tensor(labels, dtype=torch.long)

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        return {"input_ids": self.input_ids[idx], "labels": self.labels[idx]}

train_dataset = SentimentDataset(X_train, y_train, tokenizer, max_length)
test_dataset = SentimentDataset(X_test, y_test, tokenizer, max_length)

train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)

class TextCNN(nn.Module):
    def __init__(self, vocab_size, embed_dim, num_classes, num_filters=100, filter_sizes=[3, 4, 5], dropout=0.5):
        super(TextCNN, self).__init__()
        self.embedding = nn.Embedding(vocab_size, embed_dim)
        self.convs = nn.ModuleList([nn.Conv1d(embed_dim, num_filters, kernel_size=f) for f in filter_sizes])
        self.fc = nn.Linear(num_filters * len(filter_sizes), num_classes)
        self.dropout = nn.Dropout(dropout)

    def forward(self, x):
        x = self.embedding(x.long()).permute(0, 2, 1)
        x = [torch.relu(conv(x)).max(dim=2)[0] for conv in self.convs]
        x = torch.cat(x, dim=1)
        x = self.dropout(x)
        return self.fc(x)

vocab_size = tokenizer.vocab_size
embed_dim = 128
num_classes = 3

model = TextCNN(vocab_size, embed_dim, num_classes).to(device)
criterion = nn.CrossEntropyLoss()
optimizer = AdamW(model.parameters(), lr=2e-5)

accuracy_results = []
f1_results = []
recall_results = []

best_epoch = 0
best_accuracy = 0.0
best_f1 = 0.0
best_recall = 0.0

for epoch in range(1, 7):
    model.train()
    start_time = time.time()
    for batch in train_loader:
        optimizer.zero_grad()
        inputs, labels = batch["input_ids"].to(device), batch["labels"].to(device)
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
    train_time = time.time() - start_time

    model.eval()
    total_infer_time = 0
    all_preds, all_labels = [], []
    with torch.no_grad():
        for batch in test_loader:
            inputs, labels = batch["input_ids"].to(device), batch["labels"].to(device)
            start_infer = time.time()
            outputs = model(inputs)
            total_infer_time += time.time() - start_infer
            preds = torch.argmax(outputs, dim=1).cpu().numpy()
            all_preds.extend(preds)
            all_labels.extend(labels.cpu().numpy())

    avg_infer_time = total_infer_time / len(test_dataset)

    acc = accuracy_score(all_labels, all_preds)
    f1_macro = f1_score(all_labels, all_preds, average='macro')
    f1_micro = f1_score(all_labels, all_preds, average='micro')
    f1_weighted = f1_score(all_labels, all_preds, average='weighted')
    recall_macro = recall_score(all_labels, all_preds, average='macro')
    recall_micro = recall_score(all_labels, all_preds, average='micro')
    recall_weighted = recall_score(all_labels, all_preds, average='weighted')
    precision_macro = precision_score(all_labels, all_preds, average='macro')
    precision_micro = precision_score(all_labels, all_preds, average='micro')
    precision_weighted = precision_score(all_labels, all_preds, average='weighted')
    cm = confusion_matrix(all_labels, all_preds)

    num_params = sum(p.numel() for p in model.parameters())

    print(f"=== Epoch {epoch} ===")
    print(f"Accuracy: {acc:.4f}")
    print(f"Precision - Macro: {precision_macro:.4f}, Micro: {precision_micro:.4f}, Weighted: {precision_weighted:.4f}")
    print(f"Recall    - Macro: {recall_macro:.4f}, Micro: {recall_micro:.4f}, Weighted: {recall_weighted:.4f}")
    print(f"F1-Score  - Macro: {f1_macro:.4f}, Micro: {f1_micro:.4f}, Weighted: {f1_weighted:.4f}")
    print("Confusion Matrix:")
    print(cm)
    print(f"Model Parameter Size: {num_params}")
    print(f"Training Time per Epoch: {train_time:.2f} seconds")
    print(f"Inference Time per Sample: {avg_infer_time:.4f} seconds")

    accuracy_results.append(acc)
    f1_results.append(f1_weighted)
    recall_results.append(recall_weighted)

    if acc > best_accuracy:
        best_epoch = epoch
        best_accuracy = acc
        best_f1 = f1_weighted
        best_recall = recall_weighted

print(f"\nBEST Epoch: {best_epoch}")
print(f"BEST Accuracy: {best_accuracy:.4f}")
print(f"BEST F1-score (weighted): {best_f1:.4f}")
print(f"BEST Recall (weighted): {best_recall:.4f}")

print("Accuracy Curve:", accuracy_results)
print("F1 Curve:", f1_results)
print("Recall Curve:", recall_results)

"""# GPT-2"""

import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments
from torch.optim import AdamW
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix
import pandas as pd
import time
from torch.utils.data import Dataset

df = pd.read_parquet('/content/0000.parquet')
print(df.head())

sentiment_mapping = {'negative': 0, 'neutral': 1, 'positive': 2}
df['sentiment_label'] = df['airline_sentiment'].map(sentiment_mapping)

texts = df['text'].tolist()
labels = df['sentiment_label'].tolist()

X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)

model_name = "gpt2"
tokenizer = AutoTokenizer.from_pretrained(model_name)
if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token

model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)
model.config.pad_token_id = tokenizer.pad_token_id
model.resize_token_embeddings(len(tokenizer))

max_length = 64

class SentimentDataset(Dataset):
    def __init__(self, texts, labels, tokenizer, max_length=64):
        self.encodings = tokenizer(texts, truncation=True, padding="max_length", max_length=max_length)
        self.labels = torch.tensor(labels)

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx])
        return item

train_dataset = SentimentDataset(X_train, y_train, tokenizer, max_length)
test_dataset = SentimentDataset(X_test, y_test, tokenizer, max_length)

optimizer = AdamW(model.parameters(), lr=2e-5)

epochs = range(1, 7)
accuracy_results = []
f1_results = []
recall_results = []

best_epoch = 0
best_accuracy = 0.0
best_f1 = 0.0
best_recall = 0.0

for num_epochs in epochs:
    training_args = TrainingArguments(
        output_dir=f'./results_{num_epochs}',
        num_train_epochs=num_epochs,
        per_device_train_batch_size=8,
        per_device_eval_batch_size=8,
        warmup_steps=500,
        weight_decay=0.01,
        logging_dir=f'./logs_{num_epochs}',
        evaluation_strategy="epoch",
        save_strategy="epoch",
        load_best_model_at_end=True,
        save_total_limit=2,
        logging_steps=500,
    )

    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=test_dataset,
        optimizers=(optimizer, None)
    )

    start_train_time = time.time()
    trainer.train()
    train_time = time.time() - start_train_time

    start_infer_time = time.time()
    predictions = trainer.predict(test_dataset)
    infer_time = (time.time() - start_infer_time) / len(test_dataset)

    y_pred = torch.argmax(torch.tensor(predictions.predictions), axis=1).numpy()

    acc = accuracy_score(y_test, y_pred)
    f1_macro = f1_score(y_test, y_pred, average='macro')
    f1_micro = f1_score(y_test, y_pred, average='micro')
    f1_weighted = f1_score(y_test, y_pred, average='weighted')
    recall_macro = recall_score(y_test, y_pred, average='macro')
    recall_micro = recall_score(y_test, y_pred, average='micro')
    recall_weighted = recall_score(y_test, y_pred, average='weighted')
    precision_macro = precision_score(y_test, y_pred, average='macro')
    precision_micro = precision_score(y_test, y_pred, average='micro')
    precision_weighted = precision_score(y_test, y_pred, average='weighted')
    cm = confusion_matrix(y_test, y_pred)

    num_params = sum(p.numel() for p in model.parameters())

    print(f"=== Epoch {num_epochs} ===")
    print(f"Accuracy: {acc:.4f}")
    print(f"Precision - Macro: {precision_macro:.4f}, Micro: {precision_micro:.4f}, Weighted: {precision_weighted:.4f}")
    print(f"Recall    - Macro: {recall_macro:.4f}, Micro: {recall_micro:.4f}, Weighted: {recall_weighted:.4f}")
    print(f"F1-Score  - Macro: {f1_macro:.4f}, Micro: {f1_micro:.4f}, Weighted: {f1_weighted:.4f}")
    print("Confusion Matrix:")
    print(cm)
    print(f"Model Parameter Size: {num_params}")
    print(f"Training Time per Epoch: {train_time:.2f} seconds")
    print(f"Inference Time per Sample: {infer_time:.4f} seconds")

    accuracy_results.append(acc)
    f1_results.append(f1_weighted)
    recall_results.append(recall_weighted)

    if acc > best_accuracy:
        best_epoch = num_epochs
        best_accuracy = acc
        best_f1 = f1_weighted
        best_recall = recall_weighted

print(f"\nBEST Epoch: {best_epoch}")
print(f"BEST Accuracy: {best_accuracy:.4f}")
print(f"BEST F1-score (weighted): {best_f1:.4f}")
print(f"BEST Recall (weighted): {best_recall:.4f}")

print("Accuracy Curve:", accuracy_results)
print("F1 Curve:", f1_results)
print("Recall Curve:", recall_results)

"""# LSTM"""

import torch
import torch.nn as nn
from torch.optim import AdamW
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix
import pandas as pd
import time
from torch.utils.data import Dataset, DataLoader
from transformers import AutoTokenizer

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

df = pd.read_parquet('/content/0000.parquet')
print(df.head())

sentiment_mapping = {'negative': 0, 'neutral': 1, 'positive': 2}
df['sentiment_label'] = df['airline_sentiment'].map(sentiment_mapping)

texts = df['text'].tolist()
labels = df['sentiment_label'].tolist()

X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)

tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

max_length = 64

class SentimentDataset(Dataset):
    def __init__(self, texts, labels, tokenizer, max_length=64):
        self.encodings = tokenizer(texts, truncation=True, padding="max_length", max_length=max_length, return_tensors="pt")
        self.labels = torch.tensor(labels)

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        item = {key: val[idx] for key, val in self.encodings.items()}
        item['labels'] = self.labels[idx]
        return item

train_dataset = SentimentDataset(X_train, y_train, tokenizer, max_length)
test_dataset = SentimentDataset(X_test, y_test, tokenizer, max_length)

train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)

class LSTMSentiment(nn.Module):
    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes, num_layers=2, dropout=0.5):
        super(LSTMSentiment, self).__init__()
        self.embedding = nn.Embedding(vocab_size, embed_dim)
        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers=num_layers, batch_first=True, dropout=dropout)
        self.fc = nn.Linear(hidden_dim, num_classes)
        self.dropout = nn.Dropout(dropout)

    def forward(self, x):
        x = self.embedding(x)
        _, (hidden, _) = self.lstm(x)
        x = self.dropout(hidden[-1])
        return self.fc(x)

vocab_size = tokenizer.vocab_size
embed_dim = 128
hidden_dim = 256
num_classes = 3

model = LSTMSentiment(vocab_size, embed_dim, hidden_dim, num_classes).to(device)
criterion = nn.CrossEntropyLoss()
optimizer = AdamW(model.parameters(), lr=2e-5)

accuracy_results = []
f1_results = []
recall_results = []

best_epoch = 0
best_accuracy = 0.0
best_f1 = 0.0
best_recall = 0.0

for epoch in range(1, 7):
    model.train()
    start_time = time.time()
    for batch in train_loader:
        optimizer.zero_grad()
        inputs, labels = batch["input_ids"].to(device), batch["labels"].to(device)
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
    train_time = time.time() - start_time

    model.eval()
    total_infer_time = 0
    all_preds, all_labels = [], []
    with torch.no_grad():
        for batch in test_loader:
            inputs, labels = batch["input_ids"].to(device), batch["labels"].to(device)
            infer_start = time.time()
            outputs = model(inputs)
            total_infer_time += time.time() - infer_start
            preds = torch.argmax(outputs, dim=1).cpu().numpy()
            all_preds.extend(preds)
            all_labels.extend(labels.cpu().numpy())

    avg_infer_time = total_infer_time / len(test_dataset)

    acc = accuracy_score(all_labels, all_preds)
    f1_macro = f1_score(all_labels, all_preds, average='macro')
    f1_micro = f1_score(all_labels, all_preds, average='micro')
    f1_weighted = f1_score(all_labels, all_preds, average='weighted')
    recall_macro = recall_score(all_labels, all_preds, average='macro')
    recall_micro = recall_score(all_labels, all_preds, average='micro')
    recall_weighted = recall_score(all_labels, all_preds, average='weighted')
    precision_macro = precision_score(all_labels, all_preds, average='macro')
    precision_micro = precision_score(all_labels, all_preds, average='micro')
    precision_weighted = precision_score(all_labels, all_preds, average='weighted')
    cm = confusion_matrix(all_labels, all_preds)

    num_params = sum(p.numel() for p in model.parameters())

    print(f"=== Epoch {epoch} ===")
    print(f"Accuracy: {acc:.4f}")
    print(f"Precision - Macro: {precision_macro:.4f}, Micro: {precision_micro:.4f}, Weighted: {precision_weighted:.4f}")
    print(f"Recall    - Macro: {recall_macro:.4f}, Micro: {recall_micro:.4f}, Weighted: {recall_weighted:.4f}")
    print(f"F1-Score  - Macro: {f1_macro:.4f}, Micro: {f1_micro:.4f}, Weighted: {f1_weighted:.4f}")
    print("Confusion Matrix:")
    print(cm)
    print(f"Model Parameter Size: {num_params}")
    print(f"Training Time per Epoch: {train_time:.2f} seconds")
    print(f"Inference Time per Sample: {avg_infer_time:.4f} seconds")

    accuracy_results.append(acc)
    f1_results.append(f1_weighted)
    recall_results.append(recall_weighted)

    if acc > best_accuracy:
        best_epoch = epoch
        best_accuracy = acc
        best_f1 = f1_weighted
        best_recall = recall_weighted

print(f"\nBEST Epoch: {best_epoch}")
print(f"BEST Accuracy: {best_accuracy:.4f}")
print(f"BEST F1-score (weighted): {best_f1:.4f}")
print(f"BEST Recall (weighted): {best_recall:.4f}")

print("Accuracy Curve:", accuracy_results)
print("F1 Curve:", f1_results)
print("Recall Curve:", recall_results)

"""Epoch 1: Training Loss=0.9277, Validation Loss=0.8995, Accuracy=0.6452, F1-score=0.5060, Recall=0.6452
Epoch 2: Training Loss=0.9242, Validation Loss=0.8952, Accuracy=0.6452, F1-score=0.5060, Recall=0.6452
Epoch 3: Training Loss=0.9249, Validation Loss=0.8944, Accuracy=0.6452, F1-score=0.5060, Recall=0.6452
Epoch 4: Training Loss=0.9244, Validation Loss=0.8952, Accuracy=0.6455, F1-score=0.5068, Recall=0.6455
Epoch 5: Training Loss=0.8484, Validation Loss=0.7484, Accuracy=0.6810, F1-score=0.6177, Recall=0.6810
Epoch 6: Training Loss=0.7917, Validation Loss=0.7501, Accuracy=0.6909, F1-score=0.6194, Recall=0.6909

# Modern BERT
"""

import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments
from torch.optim import AdamW
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix
import pandas as pd
import time
from torch.utils.data import Dataset

df = pd.read_parquet('/content/0000.parquet')
print(df.head())

sentiment_mapping = {'negative': 0, 'neutral': 1, 'positive': 2}
df['sentiment_label'] = df['airline_sentiment'].map(sentiment_mapping)

texts = df['text'].tolist()
labels = df['sentiment_label'].tolist()
X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)

model_name = "answerdotai/modernbert-base"
tokenizer = AutoTokenizer.from_pretrained(model_name)

if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token

model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)
model.config.pad_token_id = tokenizer.pad_token_id
model.resize_token_embeddings(len(tokenizer))

max_length = 64

class SentimentDataset(Dataset):
    def __init__(self, texts, labels, tokenizer, max_length=64):
        self.encodings = tokenizer(texts, truncation=True, padding="max_length", max_length=max_length)
        self.labels = torch.tensor(labels)

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx])
        return item

train_dataset = SentimentDataset(X_train, y_train, tokenizer, max_length)
test_dataset = SentimentDataset(X_test, y_test, tokenizer, max_length)

optimizer = AdamW(model.parameters(), lr=2e-5)

accuracy_results, f1_results, recall_results = [], [], []
best_epoch, best_accuracy, best_f1, best_recall = 0, 0.0, 0.0, 0.0

for num_epochs in range(1, 7):
    training_args = TrainingArguments(
        output_dir=f'./results_{num_epochs}',
        num_train_epochs=num_epochs,
        per_device_train_batch_size=8,
        per_device_eval_batch_size=8,
        warmup_steps=500,
        weight_decay=0.01,
        logging_dir=f'./logs_{num_epochs}',
        evaluation_strategy="epoch",
        save_strategy="epoch",
        load_best_model_at_end=True,
        save_total_limit=2,
        logging_steps=500,
    )

    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=test_dataset,
        optimizers=(optimizer, None)
    )

    start_train_time = time.time()
    trainer.train()
    train_time = time.time() - start_train_time

    start_infer_time = time.time()
    predictions = trainer.predict(test_dataset)
    infer_time = (time.time() - start_infer_time) / len(test_dataset)

    y_pred = torch.argmax(torch.tensor(predictions.predictions), axis=1).numpy()

    acc = accuracy_score(y_test, y_pred)
    f1_macro = f1_score(y_test, y_pred, average='macro')
    f1_micro = f1_score(y_test, y_pred, average='micro')
    f1_weighted = f1_score(y_test, y_pred, average='weighted')
    recall_macro = recall_score(y_test, y_pred, average='macro')
    recall_micro = recall_score(y_test, y_pred, average='micro')
    recall_weighted = recall_score(y_test, y_pred, average='weighted')
    precision_macro = precision_score(y_test, y_pred, average='macro')
    precision_micro = precision_score(y_test, y_pred, average='micro')
    precision_weighted = precision_score(y_test, y_pred, average='weighted')
    cm = confusion_matrix(y_test, y_pred)

    num_params = sum(p.numel() for p in model.parameters())

    print(f"=== Epoch {num_epochs} ===")
    print(f"Accuracy: {acc:.4f}")
    print(f"Precision - Macro: {precision_macro:.4f}, Micro: {precision_micro:.4f}, Weighted: {precision_weighted:.4f}")
    print(f"Recall    - Macro: {recall_macro:.4f}, Micro: {recall_micro:.4f}, Weighted: {recall_weighted:.4f}")
    print(f"F1-Score  - Macro: {f1_macro:.4f}, Micro: {f1_micro:.4f}, Weighted: {f1_weighted:.4f}")
    print("Confusion Matrix:")
    print(cm)
    print(f"Model Parameter Size: {num_params}")
    print(f"Training Time per Epoch: {train_time:.2f} seconds")
    print(f"Inference Time per Sample: {infer_time:.4f} seconds")

    accuracy_results.append(acc)
    f1_results.append(f1_weighted)
    recall_results.append(recall_weighted)

    if acc > best_accuracy:
        best_epoch = num_epochs
        best_accuracy = acc
        best_f1 = f1_weighted
        best_recall = recall_weighted

print(f"\nBEST Epoch: {best_epoch}")
print(f"BEST Accuracy: {best_accuracy:.4f}")
print(f"BEST F1-score (weighted): {best_f1:.4f}")
print(f"BEST Recall (weighted): {best_recall:.4f}")

print("Accuracy Curve:", accuracy_results)
print("F1 Curve:", f1_results)
print("Recall Curve:", recall_results)

"""BEST Epoch: 1
BEST Accuracy: 0.8484
BEST F1-score: 0.8485
BEST Recall: 0.8484

# RoBERT
"""

import torch
import pandas as pd
from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments
from torch.optim import AdamW
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix
from torch.utils.data import Dataset
import time

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

df = pd.read_parquet('/content/0000.parquet')
print(df.head())

sentiment_mapping = {'negative': 0, 'neutral': 1, 'positive': 2}
df['sentiment_label'] = df['airline_sentiment'].map(sentiment_mapping)

texts = df['text'].tolist()
labels = df['sentiment_label'].tolist()
X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)

model_name = "roberta-base"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)

max_length = 128

class SentimentDataset(Dataset):
    def __init__(self, texts, labels, tokenizer, max_length=128):
        self.encodings = tokenizer(texts, truncation=True, padding="max_length", max_length=max_length)
        self.labels = torch.tensor(labels)

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx])
        return item

train_dataset = SentimentDataset(X_train, y_train, tokenizer, max_length)
test_dataset = SentimentDataset(X_test, y_test, tokenizer, max_length)

optimizer = AdamW(model.parameters(), lr=2e-5)

epochs = range(1, 7)
accuracy_results, f1_results, recall_results = [], [], []

best_epoch, best_accuracy, best_f1, best_recall = 0, 0.0, 0.0, 0.0

for num_epochs in epochs:
    training_args = TrainingArguments(
        output_dir=f'./results_{num_epochs}',
        num_train_epochs=num_epochs,
        per_device_train_batch_size=8,
        per_device_eval_batch_size=8,
        warmup_steps=500,
        weight_decay=0.01,
        logging_dir=f'./logs_{num_epochs}',
        evaluation_strategy="epoch",
        save_strategy="epoch",
        load_best_model_at_end=True,
        save_total_limit=2,
        logging_steps=500,
    )

    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=test_dataset,
        optimizers=(optimizer, None)
    )

    start_train_time = time.time()
    trainer.train()
    train_time = time.time() - start_train_time

    start_infer_time = time.time()
    predictions = trainer.predict(test_dataset)
    infer_time = (time.time() - start_infer_time) / len(test_dataset)

    y_pred = torch.argmax(torch.tensor(predictions.predictions), axis=1).numpy()

    acc = accuracy_score(y_test, y_pred)
    f1_macro = f1_score(y_test, y_pred, average='macro')
    f1_micro = f1_score(y_test, y_pred, average='micro')
    f1_weighted = f1_score(y_test, y_pred, average='weighted')
    recall_macro = recall_score(y_test, y_pred, average='macro')
    recall_micro = recall_score(y_test, y_pred, average='micro')
    recall_weighted = recall_score(y_test, y_pred, average='weighted')
    precision_macro = precision_score(y_test, y_pred, average='macro')
    precision_micro = precision_score(y_test, y_pred, average='micro')
    precision_weighted = precision_score(y_test, y_pred, average='weighted')
    cm = confusion_matrix(y_test, y_pred)

    num_params = sum(p.numel() for p in model.parameters())

    print(f"=== Epoch {num_epochs} ===")
    print(f"Accuracy: {acc:.4f}")
    print(f"Precision - Macro: {precision_macro:.4f}, Micro: {precision_micro:.4f}, Weighted: {precision_weighted:.4f}")
    print(f"Recall    - Macro: {recall_macro:.4f}, Micro: {recall_micro:.4f}, Weighted: {recall_weighted:.4f}")
    print(f"F1-Score  - Macro: {f1_macro:.4f}, Micro: {f1_micro:.4f}, Weighted: {f1_weighted:.4f}")
    print("Confusion Matrix:")
    print(cm)
    print(f"Model Parameter Size: {num_params}")
    print(f"Training Time per Epoch: {train_time:.2f} seconds")
    print(f"Inference Time per Sample: {infer_time:.4f} seconds")

    accuracy_results.append(acc)
    f1_results.append(f1_weighted)
    recall_results.append(recall_weighted)

    if acc > best_accuracy:
        best_epoch = num_epochs
        best_accuracy = acc
        best_f1 = f1_weighted
        best_recall = recall_weighted

print(f"\nBEST Epoch: {best_epoch}")
print(f"BEST Accuracy: {best_accuracy:.4f}")
print(f"BEST F1-score (weighted): {best_f1:.4f}")
print(f"BEST Recall (weighted): {best_recall:.4f}")

print("Accuracy Curve:", accuracy_results)
print("F1 Curve:", f1_results)
print("Recall Curve:", recall_results)

"""# DeBERTa"""

import pandas as pd
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments
from torch.optim import AdamW
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix
from torch.utils.data import Dataset
import time

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

df = pd.read_parquet('/content/0000.parquet')
print(df.head())

sentiment_mapping = {'negative': 0, 'neutral': 1, 'positive': 2}
df['sentiment_label'] = df['airline_sentiment'].map(sentiment_mapping)

texts = df['text'].tolist()
labels = df['sentiment_label'].tolist()

X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)

model_name = "microsoft/deberta-base"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)

optimizer = AdamW(model.parameters(), lr=2e-5)

max_length = 128

class SentimentDataset(Dataset):
    def __init__(self, texts, labels, tokenizer, max_length=128):
        self.encodings = tokenizer(texts, truncation=True, padding="max_length", max_length=max_length)
        self.labels = torch.tensor(labels)

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx])
        return item

train_dataset = SentimentDataset(X_train, y_train, tokenizer, max_length)
test_dataset = SentimentDataset(X_test, y_test, tokenizer, max_length)

accuracy_results, f1_results, recall_results = [], [], []
best_epoch, best_accuracy, best_f1, best_recall = 0, 0.0, 0.0, 0.0

for num_epochs in range(1, 7):
    training_args = TrainingArguments(
        output_dir=f'./results_{num_epochs}',
        num_train_epochs=num_epochs,
        per_device_train_batch_size=8,
        per_device_eval_batch_size=8,
        warmup_steps=500,
        weight_decay=0.01,
        logging_dir=f'./logs_{num_epochs}',
        evaluation_strategy="epoch",
        save_strategy="epoch",
        load_best_model_at_end=True,
        save_total_limit=2,
        logging_steps=500,
    )

    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=test_dataset,
        optimizers=(optimizer, None)
    )

    start_train_time = time.time()
    trainer.train()
    train_time = time.time() - start_train_time

    start_infer_time = time.time()
    predictions = trainer.predict(test_dataset)
    infer_time = (time.time() - start_infer_time) / len(test_dataset)

    y_pred = torch.argmax(torch.tensor(predictions.predictions), axis=1).numpy()

    acc = accuracy_score(y_test, y_pred)
    f1_macro = f1_score(y_test, y_pred, average='macro')
    f1_micro = f1_score(y_test, y_pred, average='micro')
    f1_weighted = f1_score(y_test, y_pred, average='weighted')
    recall_macro = recall_score(y_test, y_pred, average='macro')
    recall_micro = recall_score(y_test, y_pred, average='micro')
    recall_weighted = recall_score(y_test, y_pred, average='weighted')
    precision_macro = precision_score(y_test, y_pred, average='macro')
    precision_micro = precision_score(y_test, y_pred, average='micro')
    precision_weighted = precision_score(y_test, y_pred, average='weighted')
    cm = confusion_matrix(y_test, y_pred)

    num_params = sum(p.numel() for p in model.parameters())

    print(f"=== Epoch {num_epochs} ===")
    print(f"Accuracy: {acc:.4f}")
    print(f"Precision - Macro: {precision_macro:.4f}, Micro: {precision_micro:.4f}, Weighted: {precision_weighted:.4f}")
    print(f"Recall    - Macro: {recall_macro:.4f}, Micro: {recall_micro:.4f}, Weighted: {recall_weighted:.4f}")
    print(f"F1-Score  - Macro: {f1_macro:.4f}, Micro: {f1_micro:.4f}, Weighted: {f1_weighted:.4f}")
    print("Confusion Matrix:")
    print(cm)
    print(f"Model Parameter Size: {num_params}")
    print(f"Training Time per Epoch: {train_time:.2f} seconds")
    print(f"Inference Time per Sample: {infer_time:.4f} seconds")

    accuracy_results.append(acc)
    f1_results.append(f1_weighted)
    recall_results.append(recall_weighted)

    if acc > best_accuracy:
        best_epoch = num_epochs
        best_accuracy = acc
        best_f1 = f1_weighted
        best_recall = recall_weighted

print(f"\nBEST Epoch: {best_epoch}")
print(f"BEST Accuracy: {best_accuracy:.4f}")
print(f"BEST F1-score (weighted): {best_f1:.4f}")
print(f"BEST Recall (weighted): {best_recall:.4f}")

print("Accuracy Curve:", accuracy_results)
print("F1 Curve:", f1_results)
print("Recall Curve:", recall_results)